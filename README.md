
# Console Application Development Using Numerical Methods

---

## üìå Table of Contents

<details>
<summary><strong>Project Overview</strong></summary>
  
- [Introduction](#introduction)
- [Project Overview](#project-overview)
- [Structure of Each Method](#structure-of-each-method)
- [Execution Flow](#execution-flow)
- [Input and Output Format](#input-and-output-format)
- [Technologies Used](#technologies-used)
- [Contributors](#contributors)
- [License](#license)

</details>

#### [Methods Implemented](#methods-implemented)

- **[Solution of Linear Equations](#solution-of-linear-equations)**

  <details>
  <summary><strong>Gauss Elimination Method</strong></summary>

  - [Theory](#gauss-elimination-theory)
  - [Code](#gauss-elimination-code)
  - [Input](#gauss-elimination-input)
  - [Output](#gauss-elimination-output)

  </details>

  <details>
  <summary><strong>Gauss Jordan Elimination Method</strong></summary>

  - [Theory](#gauss-jordan-theory)
  - [Code](#gauss-jordan-code)
  - [Input](#gauss-jordan-input)
  - [Output](#gauss-jordan-output)

  </details>

  <details>
  <summary><strong>LU Decomposition Method</strong></summary>

  - [Theory](#lu-decomposition-theory)
  - [Code](#lu-decomposition-code)
  - [Input](#lu-decomposition-input)
  - [Output](#lu-decomposition-output)

  </details>

  <details>
  <summary><strong>Matrix Inversion Method</strong></summary>

  - [Theory](#matrix-inversion-theory)
  - [Code](#matrix-inversion-code)
  - [Input](#matrix-inversion-input)
  - [Output](#matrix-inversion-output)

  </details>

- **[Solution of Non-linear Equations](#solution-of-non-linear-equations)**

  <details>
  <summary><strong>Bisection Method</strong></summary>

  - [Theory](#bisection-theory)
  - [Code](#bisection-code)
  - [Input](#bisection-input)
  - [Output](#bisection-output)

  </details>

  <details>
  <summary><strong>False Position Method</strong></summary>

  - [Theory](#false-position-theory)
  - [Code](#false-position-code)
  - [Input](#false-position-input)
  - [Output](#false-position-output)

  </details>

  <details>
  <summary><strong>Secant Method</strong></summary>

  - [Theory](#secant-theory)
  - [Code](#secant-code)
  - [Input](#secant-input)
  - [Output](#secant-output)

  </details>

  <details>
  <summary><strong>Newton-Raphson Method</strong></summary>

  - [Theory](#newton-raphson-theory)
  - [Code](#newton-raphson-code)
  - [Input](#newton-raphson-input)
  - [Output](#newton-raphson-output)

  </details>

- **[Solution of Differential Equations](#solution-of-differential-equations)**

  <details>
  <summary><strong>Runge-Kutta Method</strong></summary>

  - [Theory](#runge-kutta-theory)
  - [Code](#runge-kutta-code)
  - [Input](#runge-kutta-input)
  - [Output](#runge-kutta-output)

  </details>

- **[Interpolation and Approximation](#interpolation-and-approximation)**

  <details>
  <summary><strong>Newton Forward Interpolation</strong></summary>

  - [Theory](#newton-forward-theory)
  - [Code](#newton-forward-code)
  - [Input](#newton-forward-input)
  - [Output](#newton-forward-output)

  </details>

  <details>
  <summary><strong>Newton Backward Interpolation</strong></summary>

  - [Theory](#newton-backward-theory)
  - [Code](#newton-backward-code)
  - [Input](#newton-backward-input)
  - [Output](#newton-backward-output)

  </details>

  <details>
  <summary><strong>Newton Divided Difference Interpolation</strong></summary>

  - [Theory](#newton-divided-theory)
  - [Code](#newton-divided-code)
  - [Input](#newton-divided-input)
  - [Output](#newton-divided-output)

  </details>

- **[Numerical Integration](#numerical-integration)**

  <details>
  <summary><strong>Simpson‚Äôs 1/3rd Rule</strong></summary>

  - [Theory](#simpson-one-third-theory)
  - [Code](#simpson-one-third-code)
  - [Input](#simpson-one-third-input)
  - [Output](#simpson-one-third-output)

  </details>

  <details>
  <summary><strong>Simpson‚Äôs 3/8th Rule</strong></summary>

  - [Theory](#simpson-three-eighth-theory)
  - [Code](#simpson-three-eighth-code)
  - [Input](#simpson-three-eighth-input)
  - [Output](#simpson-three-eighth-output)

  </details>

- **[Numerical Differentiation](#numerical-differentiation)**

  <details>
  <summary><strong>Forward Interpolation Differentiation</strong></summary>

  - [Theory](#forward-diff-theory)
  - [Code](#forward-diff-code)
  - [Input](#forward-diff-input)
  - [Output](#forward-diff-output)

  </details>

  <details>
  <summary><strong>Backward Interpolation Differentiation</strong></summary>

  - [Theory](#backward-diff-theory)
  - [Code](#backward-diff-code)
  - [Input](#backward-diff-input)
  - [Output](#backward-diff-output)

  </details>

- **[Curve Fitting Regression](#curve-fitting-regression)**

  <details>
  <summary><strong>Least Squares Regression (Linear)</strong></summary>

  - [Theory](#ls-linear-theory)
  - [Code](#ls-linear-code)
  - [Input](#ls-linear-input)
  - [Output](#ls-linear-output)

  </details>

  <details>
  <summary><strong>Least Squares Regression (Transcendental)</strong></summary>

  - [Theory](#ls-trans-theory)
  - [Code](#ls-trans-code)
  - [Input](#ls-trans-input)
  - [Output](#ls-trans-output)

  </details>

  <details>
  <summary><strong>Least Squares Regression (Polynomial)</strong></summary>

  - [Theory](#ls-poly-theory)
  - [Code](#ls-poly-code)
  - [Input](#ls-poly-input)
  - [Output](#ls-poly-output)

  </details>

---

## üìñ Introduction
This project is a **console-based numerical methods application** developed as part of an academic group project under the **Department of Computer Science and Engineering (CSE)**.  
The application demonstrates the practical implementation of fundamental numerical techniques used to solve linear and non-linear equations, differential equations, interpolation, numerical integration, numerical differentiation, and curve fitting problems.

Each numerical method is presented in a structured manner including **theory, source code, sample input, and corresponding output**, ensuring both conceptual clarity and implementation understanding.

---

## üîç Project Overview
- **Project Type:** Academic Group Project  
- **Application Type:** Console-based Application  
- **Domain:** Numerical Methods  
- **Group Members:** 3  

The application allows users to select a numerical method from a menu, provide necessary inputs, and obtain numerical results.

---

## üßÆ Methods Implemented

### Solution of Linear Equations

### Gauss Elimination Method

#### Gauss Elimination Theory
[Add your theory content here]

#### Gauss Elimination Code
```cpp
# Add your code here
```

#### Gauss Elimination Input
```
[Add your input format here]
```

#### Gauss Elimination Output
```
[Add your output format here]
```

---  
### Gauss Jordan Elimination Method

#### Gauss Jordan Theory
[Add your theory content here]

#### Gauss Jordan Code
```cpp
# Add your code here
```

#### Gauss Jordan Input
```
[Add your input format here]
```

#### Gauss Jordan Output
```
[Add your output format here]
```

---

### LU Decomposition Method

#### LU Decomposition Theory
[Add your theory content here]

#### LU Decomposition Code
```cpp
# Add your code here
```

#### LU Decomposition Input
```
[Add your input format here]
```

#### LU Decomposition Output
```
[Add your output format here]
```

---  
### Matrix Inversion

#### Matrix Inversion Theory
[Add your theory content here]

#### Matrix Inversion Code
```cpp
# Add your code here
```

#### Matrix Inversion Input
```
[Add your input format here]
```

#### Matrix Inversion Output
```
[Add your output format here]
```  

---

### Solution of Non-linear Equations

### Bisection Method

#### Bisection Theory
The Bisection Method is a numerical technique used to determine the root of a
non-linear equation of the form `f(x) = 0`. This method is applicable when the
function is continuous in a given interval and the values of the function at
the endpoints have opposite signs.

Let the initial guesses be  
\( a \) and \( b \), such that

$$
f(a)\cdot f(b) < 0
$$

This condition ensures that at least one real root exists in the interval
\( [a, b] \), according to the Intermediate Value Theorem.

The midpoint of the interval is computed as:

$$
c = \frac{a + b}{2}
$$

The function value at the midpoint is then evaluated.

If

$$
f(c) = 0
$$

then \( c \) is the exact root of the equation.

If

$$
f(a)\cdot f(c) < 0
$$

the root lies in the interval \( [a, c] \).

If

$$
f(c)\cdot f(b) < 0
$$

the root lies in the interval \( [c, b] \).

The interval containing the root is repeatedly reduced by replacing either
\( a \) or \( b \) with \( c \). This process is continued until the length of
the interval becomes sufficiently small.

The stopping criterion is generally given by:

$$
|b - a| < \varepsilon
$$

where $$\( \varepsilon \)$$ is the prescribed tolerance.

The Bisection Method is simple, reliable, and always convergent, although its
rate of convergence is relatively slow compared to other numerical methods.


**Input Characteristics** 
- The first line contains two real numbers:  
     ```
     L R
     ```  
   - Constraint on the interval:  
     
     -50 < L < R < 50
       
   - The function $f(x)$ **must change sign** in the interval $[L, R]$, i.e., $f(L) \cdot f(R) < 0$.


**Output Characteristics** 
- All real roots of the function lying within the interval  
  [L, R]
  are displayed.

- For each root, the corresponding **sub-interval** and the **approximate root value** are shown.


#### Bisection Code
```cpp
#include <bits/stdc++.h>
using namespace std;

double func(double x){
    return x*x - 4*x - 10;
}

double bisection(double a, double b, double eps){
    double mid;
    while(fabs(b - a) >= eps){
        mid = (a + b) / 2.0;
        if(func(a) * func(mid) < 0)
            b = mid;
        else
            a = mid;
    }
    return (a + b) / 2.0;
}

int main(){
    ifstream fin("input.txt");
    ofstream fout("output.txt");

    double L, R, eps;
    fin >> L >> R >> eps;

    fout << "Given Function: f(x) = x^2 - 4x - 10\n";
    fout << "Order (Degree) of the function: 2\n\n";
    fout << "Search Interval: [" << L << ", " << R << "]\n";
    fout << "Allowed Error (epsilon): " << eps << "\n\n";
    fout << "Roots found:\n";

    int root_no = 1;

    for(double i = L; i < R; i++){
        if(func(i) * func(i + 1) < 0){
            double root = bisection(i, i + 1, eps);
            fout << "Root " << root_no
                 << " lies in interval [" << i << ", " << i + 1 << "] = "
                 << fixed << setprecision(6) << root << "\n";
            root_no++;
        }
    }

    fin.close();
    fout.close();
    return 0;
}

```

#### Bisection Input
```
-10 10
0.0001
```

#### Bisection Output
```
Given Function: f(x) = x^2 - 4x - 10
Order (Degree) of the function: 2

Search Interval: [-10, 10]
Allowed Error (epsilon): 0.0001

Roots found:
Root 1 lies in interval [-2, -1] = -1.741657
Root 2 lies in interval [5, 6] = 5.741657
```

---
### False Position Method

#### False Position Theory
[Add your theory content here]

#### False Position Code
```cpp
# Add your code here
```

#### False Position Input
```
[Add your input format here]
```

#### False Position Output
```
[Add your output format here]
```

---
### Secant Method

#### Secant Theory
[Add your theory content here]

#### Secant Code
```cpp
# Add your code here
```

#### Secant Input
```
[Add your input format here]
```

#### Secant Output
```
[Add your output format here]
```

---
### Newton-Raphson Method

#### Newton-Raphson Theory
[Add your theory content here]

#### Newton-Raphson Code
```cpp
# Add your code here
```

#### Newton-Raphson Input
```
[Add your input format here]
```

#### Newton-Raphson Output
```
[Add your output format here]
```

---

### Solution of Differential Equations

### Runge-Kutta Method

#### Runge-Kutta Theory
[Add your theory content here]

#### Runge-Kutta Code
```cpp
# Add your code here
```

#### Runge-Kutta Input
```
[Add your input format here]
```

#### Runge-Kutta Output
```
[Add your output format here]
```  

---

### Interpolation and Approximation  

### Newton Forward Interpolation

#### Newton Forward Interpolation Theory
Newton's Forward Interpolation is used to estimate the value of an unknown variable `x` which is less than the middle value of the given data. This method is applicable when the difference between any two consecutive values of `x` is constant.

Let the given data points be  $x_0, x_1, \ldots , x_n$  with corresponding values  $y_0, y_1, \ldots , y_n$.

The data must satisfy the condition:

$$
x_i - x_{i-1} = h \quad \text{(constant)}, \quad 1 \le i \le n
$$

and the interpolation point should satisfy: 

$$
x < \frac{x_0 + x_n}{2}
$$



The forward difference is defined as:

$$
\Delta y_i = y_{i+1} - y_i
$$

Higher order forward differences are:

$$
\Delta^2 y_i = \Delta(\Delta y_i)
$$

$$
\Delta^3 y_i = \Delta(\Delta^2 y_i)
$$

and so on.



Let

$$
u = \frac{x - x_0}{h}
$$

Then the Newton's Forward Interpolation formula is given by

$$
y(x) = y_0+ u \Delta y_0+ \frac{u(u-1)}{2!} \Delta^2 y_0+ \frac{u(u-1)(u-2)}{3!} \Delta^3 y_0+ \cdots
$$

**Input Characteristics:**

The input starts with an integer $n$ - the number of variable $x$ and $y$.

The second line contains $n$ integers $x_i$ for $1\le i \le n$.

The third line contains $n$ integers $y_i$ for $1\le i \le n$.

The final line contains the value of $x$ for which the interpolated value is to be determined.

**Output Characteristics:**

Firstly, the output shows the Forward Difference Table.

Secondly, the interpolated value of $y$ is displayed.

#### Newton Forward Interpolation Code
```cpp
#include <bits/stdc++.h>
using namespace std;

long long fact(int n){
    long long f = 1;
    for(int i = 2; i <= n; i++){
        f *= i;
    }
    return f;
}

int main(){
    ifstream fin("input.txt");
    ofstream fout("output.txt");

    if(!fin){
        cout<<"Error: input.txt not found!"<<endl;
        return 0;
    }
    if(!fout){
        cout<<"Error: Can't open output.txt!"<<endl;
        return 0;
    }

    int n;
    fin>>n;

    double x[n], y[n][10];

    for(int i = 0; i < n; i++){
        fin>>x[i];
    }

    for(int i = 0; i < n; i++){
        fin>>y[i][0];
    }

    for(int j = 1; j < n; j++){
        for(int i = 0; i < n - j; i++){
            y[i][j] = y[i + 1][j - 1] - y[i][j - 1];
        }
    }

    fout<<"\nForward Difference Table:\n";
    for(int i = 0; i < n; i++){
        fout<<x[i]<<"\t";
        for(int j = 0; j < n - i; j++){
            fout<<y[i][j]<<"\t";
        }
        fout<<endl;
    }

    double value;
    fin>>value;

    double h = x[1] - x[0];
    double u = (value - x[0]) / h;

    double sum = y[0][0];
    double u_term = 1;

    for(int i = 1; i < n; i++){
        u_term *= (u - (i - 1));
        sum += (u_term * y[0][i]) / fact(i);
    }

    fout<<"\nInterpolated value at x = "<<value<<" is "<<sum<<endl;

    fin.close();
    fout.close();
    return 0;
}
```

#### Newton Forward Interpolation Input

```
4
3 5 7 9
180 150 120 90
4
```


#### Newton Forward Interpolation Output
```

Forward Difference Table:
3	180	-30	0	0	
5	150	-30	0	
7	120	-30	
9	90	

Interpolated value at x = 4 is 165
```



---
### Newton Backward Interpolation

#### Newton Backward Interpolation Theory
Newton's Backward Interpolation is used to estimate the value of an unknown variable `x` which is greater than the middle value of the given data. This method is applicable when the difference between any two consecutive values of `x` is constant.

Let the given data points be $x_0, x_1, \ldots , x_n$ with corresponding values $y_0, y_1, \ldots , y_n$.

The data must satisfy the condition:

$$
x_i - x_{i-1} = h \quad \text{(constant)}, \quad 1 \le i \le n
$$

and the interpolation point should satisfy:

$$
x > \frac{x_0 + x_n}{2}
$$

The backward difference is defined as:

$$
\nabla y_i = y_i - y_{i-1}
$$

Higher order backward differences are:

$$
\nabla^2 y_i = \nabla(\nabla y_i)
$$

$$
\nabla^3 y_i = \nabla(\nabla^2 y_i)
$$

and so on.

Let

$$
u = \frac{x - x_n}{h}
$$

Then the Newton's Backward Interpolation formula is given by

$$
y(x) = y_n+ u \nabla y_n+ \frac{u(u+1)}{2!} \nabla^2 y_n+ \frac{u(u+1)(u+2)}{3!} \nabla^3 y_n+ \cdots
$$

**Input Characteristics:**

The input starts with an integer $n$ - the number of variable $x$ and $y$.

The second line contains $n$ integers $x_i$ for $1\le i \le n$.

The third line contains $n$ integers $y_i$ for $1\le i \le n$.

The final line contains the value of $x$ for which the interpolated value is to be determined.

**Output Characteristics:**

Firstly, the output shows the Backward Difference Table.

Secondly, the interpolated value of $y$ is displayed.

#### Newton Backward Interpolation Code
```cpp
#include <bits/stdc++.h>
using namespace std;

long long fact(int n){
    long long f = 1;
    for(int i=2; i<=n; i++){
        f *= i;
    }
    return f;
}

int main(){
    ifstream fin("input.txt");
    ofstream fout("output.txt");

    if(!fin){
        cout<<"Error: input.txt not found!"<<endl;
        return 0;
    }
    if(!fout){
        cout<<"Error: Can't open output.txt!"<<endl;
        return 0;
    }
    
    int n;
    fin>>n;

    double x[n], y[n][10];
    for(int i=0; i<n; i++){
        fin>>x[i];
    }
    for(int i=0; i<n; i++){
        fin>>y[i][0];
    }

    for(int j=1; j<n; j++){
        for(int i=n-1; i>=j; i--){
            y[i][j] = y[i][j-1] - y[i-1][j-1];
        }
    }

    fout<<"\nBackward Difference Table:\n";
    for(int i=0; i<n; i++){
        fout<<x[i]<<"\t";
        for(int j=0; j<=i; j++){
            fout<<y[i][j]<<"\t";
        }
        fout<<endl;
    }

    double val;
    fin>>val;
    
    double h = x[1] - x[0];
    double v = (val - x[n-1]) / h;

    double sum = y[n-1][0];
    double v_term = 1;
    for(int i=1; i<n; i++){
        v_term *= (v + (i-1));
        sum += (v_term * y[n-1][i]) / fact(i);
    }

    fout<<"\nInterpolated value at x = "<<val<<" is "<<sum<<endl;

    fin.close();
    fout.close();
    return 0;
}
```

#### Newton Backward Interpolation Input
```
5
24 28 32 36 40
28.06 30.19 32.75 34.94 40
33
```

#### Newton Backward Interpolation Output
```

Backward Difference Table:
24	28.06	
28	30.19	2.13	
32	32.75	2.56	0.43	
36	34.94	2.19	-0.37	-0.8	
40	40	5.06	2.87	3.24	4.04	

Interpolated value at x = 33 is 33.2747
```

---
### Newton Divided Difference Interpolation

#### Newton Divided Difference Interpolation Theory
Newton's Divided Difference Interpolation is used to estimate the value of an unknown variable `x` when the data points are not equally spaced. This method constructs an interpolating polynomial that passes through all given data points.

Let the given data points be $x_0, x_1, x_2, \ldots , x_n$ with corresponding values $y_0, y_1, y_2, \ldots , y_n$, where the values of `x` are not necessarily equally spaced.

The first divided difference is defined as:

$$
f[x_i, x_{i+1}] = \frac{y_{i+1} - y_i}{x_{i+1} - x_i}
$$

The second divided difference is defined as:

$$
f[x_i, x_{i+1}, x_{i+2}] =
\frac{f[x_{i+1}, x_{i+2}] - f[x_i, x_{i+1}]}{x_{i+2} - x_i}
$$

Higher order divided differences are defined recursively as:

$$
f[x_i, x_{i+1}, \ldots , x_{i+k}] =
\frac{f[x_{i+1}, \ldots , x_{i+k}] - f[x_i, \ldots , x_{i+k-1}]}{x_{i+k} - x_i}
$$

The Newton's Divided Difference Interpolation formula is given by

$$
\begin{aligned}
y(x) = & y_0+ (x - x_0) f[x_0, x_1]+ (x - x_0)(x - x_1) f[x_0, x_1, x_2] \\& + (x - x_0)(x - x_1)(x - x_2) f[x_0, x_1, x_2, x_3]+ \cdots\end{aligned}
$$

This method is suitable for interpolation when the data points are unequally spaced and provides a flexible way to construct the interpolating polynomial.

**Input Characteristics:**

The input starts with an integer $n$ - the number of variable $x$ and $y$.

The second line contains $n$ integers $x_i$ for $1\le i \le n$.

The third line contains $n$ integers $y_i$ for $1\le i \le n$.

The final line contains the value of $x$ for which the interpolated value is to be determined.

**Output Characteristics:**

Firstly, the output shows the Divided Difference Table.

Secondly, the interpolated value of $y$ is displayed.

#### Newton Divided Difference Interpolation Code
```cpp
#include <bits/stdc++.h>
using namespace std;

int main() {
    ifstream fin("input.txt");
    ofstream fout("output.txt");

    if(!fin){
        cout<<"Error: input.txt not found!"<<endl;
        return 0;
    }
    if(!fout){
        cout<<"Error: Can't open output.txt!"<<endl;
        return 0;
    }
    
    int n;
    fin>>n;
    double x[n], y[n][n];

    for(int i=0; i<n; i++){
        fin>>x[i];
    }
    for(int i=0; i<n; i++){
        fin>>y[i][0];
    }

    for(int j=1; j<n; j++){
        for(int i=0; i<n-j; i++){
            y[i][j] = ( y[i+1][j-1] - y[i][j-1] ) / ( x[i+j] - x[i] );
        }
    }
    fout<<"\nDivided Difference Table:\n";
    for(int i=0; i<n; i++){
        fout<<x[i]<<"\t";
        for(int j=0; j<n-i; j++){
            fout<<y[i][j]<<"\t";
        }
        fout<<endl;
    }

    double val;
    fin>>val;

    double sum = y[0][0];
    double term = 1;

    for(int i=1; i<n; i++){
        term *= (val - x[i-1]);
        sum += term*y[0][i];
    }

    fout<<"\nInterpolated value at x = "<<val<<" is "<<sum<<endl;

    fin.close();
    fout.close();
    return 0;
}
```

#### Newton Divided Difference Interpolation Input
```
4
1 4 6 5
0 1.386294 1.79175 1.609438
2
```

#### Newton Divided Difference Interpolation Output
```

Divided Difference Table:
1	0	0.462098	-0.051874	0.0078645	
4	1.38629	0.202728	-0.020416	
6	1.79175	0.182312	
5	1.60944	

Interpolated value at x = 2 is 0.628762
```

---

### Numerical Integration
 
### Simpson‚Äôs 1/3rd Rule Method

#### Simpson‚Äôs 1/3rd Rule Theory
Simpson‚Äôs 1/3rd Rule is a numerical integration method used to approximate the definite integral of a function when the integrand is known at equally spaced points. This method provides better accuracy than the Trapezoidal Rule for smooth functions.

Let the interval of integration be $[a, b]$ and divide it into an even number of subintervals $n$, where the width of each subinterval is given by:

$$
h = \frac{b - a}{n}, \quad \text{where } n \text{ is even}
$$

Let the ordinates of the function be:

$$
y_0 = f(a),\; y_1 = f(a+h),\; y_2 = f(a+2h),\; \ldots ,\; y_n = f(b)
$$

Then the Simpson‚Äôs 1/3rd Rule formula is given by

$$
\int_a^b f(x)dx \approx \frac{h}{3}\left[y_0 + y_n+ 4(y_1 + y_3 + \cdots + y_{n-1})+ 2(y_2 + y_4 + \cdots + y_{n-2})\right]
$$

This method is applicable when the function is continuous and smooth over the interval of integration and the number of subintervals is even.

**Input Characteristics:**

Input is taken by a single line containing 3 integers : $a,b,n$ - lower limit, upper limit & number of intervals.

**Output Characteristics:**

In the output, the function is shown.

Then the upper limit, lower limit & number of intervals are shown.

At last, the integral value is shown.

#### Simpson‚Äôs 1/3rd Rule Code
```cpp
#include <bits/stdc++.h>
using namespace std;

double func(double x){
    return 1/(1+x*x);
}

double simpson13(double a, double b, int n){
    double h = (b-a) / n;
    double x[n+1], y[n+1];

    for(int i=0; i<n+1; i++){
        x[i] = a + i*h;
        y[i] = func(x[i]);
    }

    double ans = 0;
    for(int i=0; i<n+1; i++){
        if(i==0 || i==n){
            ans += y[i];
        }
        else if(i%2){
            ans += 4*y[i];
        }
        else{
            ans += 2*y[i];
        }
    }
    ans = ans*(h/3);
    return ans;
}

int main() {
    ifstream fin("input.txt");
    ofstream fout("output.txt");

    if(!fin){
        cout<<"Error: input.txt not found!"<<endl;
        return 0;
    }
    if(!fout){
        cout<<"Error: Can't open output.txt!"<<endl;
        return 0;
    }

    double a, b;
    int n;
    fin>>a>>b>>n;

    fout<<"\nf(x) = 1 / (1 + x * x)\n"<<"where, lower limit = "<<a<<" , upper limit = "<<b<<" , Number of intervals = "<<n<<endl;
    fout<<"\nThe value of integral: "<<simpson13(a, b, n)<<endl;

    fin.close();
    fout.close();
    return 0;
}
```

#### Simpson‚Äôs 1/3rd Rule Input
```
0 1 4
```

#### Simpson‚Äôs 1/3rd Rule Output
```

f(x) = 1 / (1 + x * x)
where, lower limit = 0 , upper limit = 1 , Number of intervals = 4

The value of integral: 0.785392
```

---
### Simpson‚Äôs 3/8th Rule Method

#### Simpson‚Äôs 3/8th Rule Theory
[Add your theory content here]

#### Simpson‚Äôs 3/8th Rule Code
```cpp
# Add your code here
```

#### Simpson‚Äôs 3/8th Rule Input
```
[Add your input format here]
```

#### Simpson‚Äôs 3/8th Rule Output
```
[Add your output format here]
```

---

### Numerical Differentiation 

### Differentiation using Forward Interpolation

#### Differentiation using Forward Interpolation Theory
[Add your theory content here]

#### Differentiation using Forward Interpolation Code
```cpp
# Add your code here
```

#### Differentiation using Forward Interpolation Input
```
[Add your input format here]
```

#### Differentiation using Forward Interpolation Output
```
[Add your output format here]
```

---
### Differentiation using Backward Interpolation

#### Differentiation using Backward Interpolation Theory
[Add your theory content here]

#### Differentiation using Backward Interpolation Code
```cpp
# Add your code here
```

#### Differentiation using Backward Interpolation Input
```
[Add your input format here]
```

#### Differentiation using Backward Interpolation Output
```
[Add your output format here]
```

---

### Curve Fitting Regression 

### Least Squares Regression (Linear) Method

#### Least Squares Regression (Linear) Theory
[Add your theory content here]

#### Least Squares Regression (Linear) Code
```cpp
# Add your code here
```

#### Least Squares Regression (Linear) Input
```
[Add your input format here]
```

#### Least Squares Regression (Linear) Output
```
[Add your output format here]
```

---
### Least Squares Regression (Transcendental) Method

#### Least Squares Regression (Transcendental) Theory
[Add your theory content here]

#### Least Squares Regression (Transcendental) Code
```cpp
# Add your code here
```

#### Least Squares Regression (Transcendental) Input
```
[Add your input format here]
```

#### Least Squares Regression (Transcendental) Output
```
[Add your output format here]
```

---
### Least Squares Regression (Polynomial) Method

#### Least Squares Regression (Polynomial) Theory
[Add your theory content here]

#### Least Squares Regression (Polynomial) Code
```cpp
# Add your code here
```

#### Least Squares Regression (Polynomial) Input
```
[Add your input format here]
```

#### Least Squares Regression (Polynomial) Output
```
[Add your output format here]
```

---

## üß© Structure of Each Method
Each numerical method in the application consists of the following four components:

1. **Theory** ‚Äì Mathematical background and explanation  
2. **Code** ‚Äì Algorithmic implementation  
3. **Input** ‚Äì User-provided data  
4. **Output** ‚Äì Computed numerical result  

---

## üîÑ Execution Flow
1. 
2.   
3.   
4.   

---

## ‚å® Input and Output Format
- **Input:** Numerical values, matrices, initial guesses, step size, or data points  
- **Output:** Approximate solution and final result  

All interactions are performed via the console.

---

## üõ† Technologies Used
- **Programming Language:** C / C++  
- **Compiler:** GCC / g++  
- **Development Environment:** Code::Blocks / VS Code  
- **Platform:** Windows / Linux  

---

## üë• Contributors
This project was developed by a group of **three students**:

- Member 1 ‚Äì Roll No:  2207045
- Member 2 ‚Äì Roll No:  2207046
- Member 3 ‚Äì Roll No:  2207048

---

## üìú License
This project is intended **strictly for academic and educational purposes**.  
Unauthorized commercial use is prohibited.

¬© 2025 Department of Computer Science and Engineering
